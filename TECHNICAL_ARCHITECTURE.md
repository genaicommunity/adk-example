# Technical Architecture Document
# FinOps Cost Data Analyst Agent

**Version**: 2.0
**Date**: October 21, 2025
**Architecture**: Dynamic Multi-Table Discovery
**Status**: Production Ready
**Companion Document**: PRD_FinOps_Agent.md

---

## ğŸ“‹ Table of Contents

1. [System Architecture Overview](#system-architecture-overview)
2. [Component Architecture](#component-architecture)
3. [Multi-Table Discovery Workflow](#multi-table-discovery-workflow)
4. [BigQuery Toolset Architecture](#bigquery-toolset-architecture)
5. [Data Flow Diagrams](#data-flow-diagrams)
6. [API Specifications](#api-specifications)
7. [Security Architecture](#security-architecture)
8. [Deployment Architecture](#deployment-architecture)
9. [Performance Optimization](#performance-optimization)
10. [Error Handling & Resilience](#error-handling--resilience)
11. [Testing Strategy](#testing-strategy)
12. [Monitoring & Observability](#monitoring--observability)

---

## ğŸ—ï¸ System Architecture Overview

### High-Level Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         USER INTERFACE                          â”‚
â”‚                    (Natural Language Query)                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    ROOT AGENT (Orchestrator)                    â”‚
â”‚                      SequentialAgent                            â”‚
â”‚              Coordinates 4 Sub-Agents in Sequence               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â”‚    Shared State Dictionary     â”‚
                â”‚  (Data flows between agents)   â”‚
                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                       â”‚                       â”‚
        â–¼                       â–¼                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  SUB-AGENT 1     â”‚   â”‚  SUB-AGENT 2     â”‚   â”‚  SUB-AGENT 3     â”‚
â”‚ SQL Generation   â”‚â”€â”€â–¶â”‚ SQL Validation   â”‚â”€â”€â–¶â”‚Query Execution   â”‚
â”‚                  â”‚   â”‚                  â”‚   â”‚                  â”‚
â”‚ Tools:           â”‚   â”‚ Tools:           â”‚   â”‚ Tools:           â”‚
â”‚ âš¡ Schema        â”‚   â”‚ â€¢ Validation     â”‚   â”‚ â€¢ execute_sql    â”‚
â”‚   Toolset        â”‚   â”‚   Functions      â”‚   â”‚                  â”‚
â”‚ â€¢ get_table_info â”‚   â”‚ â€¢ Forbidden      â”‚   â”‚ Accesses:        â”‚
â”‚ â€¢ list_datasets  â”‚   â”‚   Keywords       â”‚   â”‚ BigQuery API     â”‚
â”‚ â€¢ list_tables    â”‚   â”‚ â€¢ SQL Parser     â”‚   â”‚                  â”‚
â”‚ â€¢ get_dataset    â”‚   â”‚                  â”‚   â”‚                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚                       â”‚                       â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚    SUB-AGENT 4       â”‚
                    â”‚  Insight Synthesis   â”‚
                    â”‚                      â”‚
                    â”‚ Tools: None          â”‚
                    â”‚ (Pure LLM)           â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    FORMATTED BUSINESS INSIGHTS                  â”‚
â”‚              (Returned to User via ADK Interface)               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

                                â”‚
                                â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚      BIGQUERY DATA SOURCES            â”‚
        â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
        â”‚  Dataset 1: cost_dataset              â”‚
        â”‚    â””â”€ cost_analysis                   â”‚
        â”‚  Dataset 2: budget_dataset            â”‚
        â”‚    â””â”€ budget                          â”‚
        â”‚  Dataset 3: usage_dataset             â”‚
        â”‚    â””â”€ resource_usage                  â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Architecture Principles

1. **Separation of Concerns**: Each agent has a single, well-defined responsibility
2. **Sequential Execution**: Agents execute in order, passing data via shared state
3. **Tool-based Capabilities**: Agents gain capabilities through specialized toolsets
4. **Dynamic Discovery**: No hardcoded schemas - all metadata fetched at runtime
5. **Security-First**: Read-only operations, SQL validation, injection prevention
6. **State-based Data Flow**: Explicit output_key mechanism for inter-agent communication

---

## ğŸ§© Component Architecture

### Code Organization & Modularity

**Modular Architecture** (Current - October 2025)

The agent codebase is organized into focused, single-purpose modules for maintainability and scalability:

```
finops-cost-data-analyst/
â”œâ”€â”€ __init__.py              # ADK discovery (exports root_agent)
â”œâ”€â”€ agent.py                 # Root SequentialAgent ONLY (52 lines)
â”œâ”€â”€ sub_agents.py            # All 4 sub-agents (124 lines)
â”œâ”€â”€ prompts.py               # Centralized prompts & business logic
â””â”€â”€ _tools/                  # Tools package
    â”œâ”€â”€ __init__.py
    â”œâ”€â”€ validation_tools.py  # SQL validation functions
    â””â”€â”€ bigquery_tools.py    # BigQuery toolsets
```

**Key Benefits**:
- âœ… **Separation of Concerns**: Orchestration vs implementation
- âœ… **Maintainability**: Each file has single, clear purpose
- âœ… **Scalability**: Easy to add new sub-agents
- âœ… **Testability**: Can test components independently
- âœ… **Readability**: Small, focused modules vs monolithic files

**File Responsibilities**:

| File | Lines | Purpose | Contents |
|------|-------|---------|----------|
| `agent.py` | 52 | Orchestration | Root SequentialAgent definition only |
| `sub_agents.py` | 124 | Implementation | All 4 LlmAgent sub-agents |
| `prompts.py` | 547 | Business Logic | All prompts, FY definitions, schema instructions |
| `_tools/bigquery_tools.py` | 95 | Data Access | BigQuery toolsets configuration |
| `_tools/validation_tools.py` | 85 | Security | SQL validation & security checks |

---

### Root Agent: FinOps Cost Analyst Orchestrator

**Type**: `SequentialAgent`
**File**: `agent.py`
**Purpose**: Orchestrates 4 sub-agents in sequential workflow

```python
root_agent = SequentialAgent(
    name="FinOpsCostAnalystOrchestrator",
    description=ROOT_AGENT_DESCRIPTION,
    sub_agents=[
        sql_generation_agent,      # Step 1
        sql_validation_agent,      # Step 2
        query_execution_agent,     # Step 3
        insight_synthesis_agent,   # Step 4
    ],
    model=os.getenv("ROOT_AGENT_MODEL", "gemini-2.0-flash-exp"),
)
```

**Responsibilities**:
- Receive user's natural language query
- Initialize shared state dictionary
- Execute sub-agents sequentially
- Return final insights to user

**Key Properties**:
- NO tools (uses sub_agents instead)
- NO output_key (terminal agent)
- Manages shared state across all sub-agents

---

### Sub-Agent 1: SQL Generation Agent

**Type**: `LlmAgent`
**File**: `sub_agents.py:46-62`
**Tools**: `bigquery_full_toolset` (schema discovery + AI analytics)
**Purpose**: Convert natural language to BigQuery SQL with dynamic table selection

#### Configuration

```python
sql_generation_agent = LlmAgent(
    model=os.getenv("ROOT_AGENT_MODEL", "gemini-2.0-flash-exp"),
    name="sql_generation",
    instruction=get_sql_generation_prompt(),
    output_key="sql_query",
    tools=[bigquery_schema_toolset],
    generate_content_config=types.GenerateContentConfig(
        temperature=0.01,  # Low temperature for deterministic SQL
    ),
)
```

#### Available Tools

| Tool | Purpose | Usage |
|------|---------|-------|
| `get_table_info` | Fetch table schema (columns, types) | Called for each discovered table |
| `get_dataset_info` | Fetch dataset metadata | Optional - for dataset description |
| `list_table_ids` | List all tables in dataset | Used in Step 3 of discovery workflow |
| `list_dataset_ids` | List all datasets in project | Used in Step 2 of discovery workflow |

#### Discovery Workflow (5 Steps)

```
Step 1: Classify Query
   â†“
   User: "What is our total cost for FY26?"
   Classification: COST query

Step 2: Discover Datasets
   â†“
   Call: list_dataset_ids(project_id="gac-prod-471220")
   Result: ["cost_dataset", "budget_dataset", "usage_dataset"]
   Match: "cost_dataset" (contains "cost")

Step 3: Discover Tables
   â†“
   Call: list_table_ids(project_id="gac-prod-471220", dataset_id="cost_dataset")
   Result: ["cost_analysis"]
   Match: "cost_analysis" (contains "cost")

Step 4: Get Schema
   â†“
   Call: get_table_info(project_id="gac-prod-471220",
                        dataset_id="cost_dataset",
                        table_id="cost_analysis")
   Result: {
     "schema": {
       "fields": [
         {"name": "date", "type": "DATE"},
         {"name": "cloud", "type": "STRING"},
         {"name": "application", "type": "STRING"},
         {"name": "cost", "type": "FLOAT64"}
       ]
     }
   }

Step 5: Generate SQL
   â†“
   SELECT SUM(cost) as total_cost
   FROM `gac-prod-471220.cost_dataset.cost_analysis`
   WHERE date BETWEEN '2025-02-01' AND '2026-01-31'
```

#### Pattern Matching Logic

**Cost Queries**: Matches `*cost*`, `*spending*`, `*expense*`
**Budget Queries**: Matches `*budget*`, `*forecast*`, `*allocation*`
**Usage Queries**: Matches `*usage*`, `*utilization*`, `*consumption*`, `*resource*`

**Multi-Table Joins**: For comparison queries (e.g., "budget vs actual"), discovers multiple tables and generates JOIN SQL.

#### Output

**State Key**: `state['sql_query']`
**Format**: Raw SQL string (no markdown, no explanations)

Example:
```sql
SELECT SUM(cost) as total_cost
FROM `gac-prod-471220.cost_dataset.cost_analysis`
WHERE date BETWEEN '2025-02-01' AND '2026-01-31'
```

---

### Sub-Agent 2: SQL Validation Agent

**Type**: `LlmAgent`
**File**: `sub_agents.py:70-83`
**Tools**: `[check_forbidden_keywords, parse_sql_query, validate_sql_security]`
**Purpose**: Validate SQL for security before execution

#### Configuration

```python
sql_validation_agent = LlmAgent(
    model=os.getenv("ROOT_AGENT_MODEL", "gemini-2.0-flash-exp"),
    name="sql_validation",
    instruction=SQL_VALIDATION_PROMPT,
    output_key="validation_result",
    tools=[
        check_forbidden_keywords,
        parse_sql_query,
        validate_sql_security,
    ],
    generate_content_config=types.GenerateContentConfig(
        temperature=0.0,  # Zero temperature for strict validation
    ),
)
```

#### Validation Tools

```python
# _tools/validation_tools.py

def check_forbidden_keywords(sql: str) -> dict:
    """Detect dangerous SQL keywords"""
    forbidden = [
        "DROP", "DELETE", "INSERT", "UPDATE", "CREATE",
        "ALTER", "TRUNCATE", "EXEC", "EXECUTE", ";", "--"
    ]
    for keyword in forbidden:
        if keyword.upper() in sql.upper():
            return {"valid": False, "reason": f"Contains forbidden keyword: {keyword}"}
    return {"valid": True}

def parse_sql_query(sql: str) -> dict:
    """Validate SQL syntax using sqlparse"""
    try:
        parsed = sqlparse.parse(sql)
        if not parsed:
            return {"valid": False, "reason": "Invalid SQL syntax"}
        return {"valid": True, "parsed": str(parsed[0])}
    except Exception as e:
        return {"valid": False, "reason": f"Parse error: {str(e)}"}

def validate_sql_security(sql: str) -> dict:
    """Complete validation (combines both checks)"""
    keyword_check = check_forbidden_keywords(sql)
    if not keyword_check["valid"]:
        return keyword_check

    syntax_check = parse_sql_query(sql)
    if not syntax_check["valid"]:
        return syntax_check

    return {"valid": True, "message": "SQL is safe"}
```

#### Validation Rules

âœ… **Allowed Keywords**: SELECT, WITH, FROM, WHERE, JOIN, GROUP BY, ORDER BY, LIMIT
âŒ **Forbidden Keywords**: DROP, DELETE, INSERT, UPDATE, CREATE, ALTER, TRUNCATE, EXEC
âŒ **Forbidden Characters**: `;` (prevents query chaining), `--` (prevents comment injection)

#### Input & Output

**Input**: `state['sql_query']` (from SQL Generation Agent)
**Output**: `state['validation_result']`

**Valid Response**:
```
VALID
```

**Invalid Response**:
```
INVALID: Contains forbidden keyword DROP
```

---

### Sub-Agent 3: Query Execution Agent

**Type**: `LlmAgent`
**File**: `sub_agents.py:90-99`
**Tools**: `bigquery_execution_toolset` (1 tool)
**Purpose**: Execute validated SQL on BigQuery

#### Configuration

```python
query_execution_agent = LlmAgent(
    model=os.getenv("ROOT_AGENT_MODEL", "gemini-2.0-flash-exp"),
    name="query_execution",
    instruction=get_query_execution_prompt(),
    output_key="query_results",
    tools=[bigquery_execution_toolset],
    generate_content_config=types.GenerateContentConfig(
        temperature=0.0,
    ),
)
```

#### Available Tool

**`execute_sql(sql: str)`** - Executes SQL query on BigQuery

From `google.adk.tools.bigquery.BigQueryToolset`:
```python
bigquery_execution_toolset = BigQueryToolset(
    tool_filter=["execute_sql"],
    bigquery_tool_config=BigQueryToolConfig(
        write_mode=WriteMode.BLOCKED,  # Security: read-only
    ),
)
```

#### Execution Flow

1. Reads validated SQL from `state['sql_query']`
2. Calls `execute_sql(sql)` via BigQuery API
3. Returns raw results to `state['query_results']`

#### Input & Output

**Input**: `state['sql_query']` (validated SQL)
**Output**: `state['query_results']`

Example:
```
total_cost
27442275.64
```

#### Error Handling

If query fails:
```
ERROR: Table not found: gac-prod-471220.cost_dataset.cost_analysis
```

---

### Sub-Agent 4: Insight Synthesis Agent

**Type**: `LlmAgent`
**File**: `sub_agents.py:106-115`
**Tools**: None (pure LLM)
**Purpose**: Transform raw query results into business insights

#### Configuration

```python
insight_synthesis_agent = LlmAgent(
    model=os.getenv("ROOT_AGENT_MODEL", "gemini-2.0-flash-exp"),
    name="insight_synthesis",
    instruction=INSIGHT_SYNTHESIS_PROMPT,
    output_key="final_insights",
    tools=None,  # No tools - pure LLM formatting
    generate_content_config=types.GenerateContentConfig(
        temperature=0.1,  # Slight creativity for formatting
    ),
)
```

#### Data Accuracy Rules (CRITICAL)

**From Prompt**:
```
YOU MUST USE EXACT VALUES FROM QUERY RESULTS. DO NOT INVENT NUMBERS.

Rules:
1. NEVER make up numbers - only use values from results
2. NEVER round excessively - keep 2 decimal places minimum
3. NEVER estimate - if not in results, say "data not available"
4. ALWAYS verify numbers match the input data
5. If results show `27442275.64`, you report `$27,442,275.64` (NOT $27M!)
```

#### Formatting Standards

- **Currency**: $27,442,275.64 (with commas)
- **Percentages**: 23.5%
- **Dates**: "February 2025" (human-friendly)
- **Context**: Explain what numbers mean
- **Trends**: Highlight patterns if comparing periods

#### Output Structure

1. **Direct Answer**: Lead with the key finding
2. **Context**: Explain timeframe/scope
3. **Breakdown**: Show components if relevant
4. **Insights**: Note patterns or anomalies

#### Example Transformation

**Input**:
```
Question: "What is total cost for FY26?"
Results:
total_cost
27442275.64
```

**Output**:
```
The total cost for FY26 (February 2025 - January 2026) was $27,442,275.64.

This represents cloud spending across all providers and applications for the current fiscal year.
```

---

## ğŸ”„ Multi-Table Discovery Workflow

### Query Type Classification

The SQL Generation Agent classifies queries into 4 categories:

#### 1. COST Queries
**Keywords**: spending, expenses, costs, "how much did we spend"
**Target Dataset**: `cost_dataset` (or `*cost*`, `*spending*`, `*expense*`)
**Target Table**: `cost_analysis` (or `*cost*`)
**Example**: "What is our total cloud cost for FY26?"

#### 2. BUDGET Queries
**Keywords**: budget, allocated, forecasted, "what is our budget"
**Target Dataset**: `budget_dataset` (or `*budget*`, `*forecast*`)
**Target Table**: `budget` (or `*budget*`, `*allocation*`)
**Example**: "What is our budget for FY26?"

#### 3. USAGE Queries
**Keywords**: utilization, consumption, hours, "how much did we use"
**Target Dataset**: `usage_dataset` (or `*usage*`, `*utilization*`)
**Target Table**: `resource_usage` (or `*usage*`, `*consumption*`)
**Example**: "How many compute hours did we use this month?"

#### 4. COMPARISON Queries
**Keywords**: "budget vs actual", variance, "are we over budget", "compare"
**Target Datasets**: Multiple (e.g., cost_dataset + budget_dataset)
**Strategy**: Generate JOIN query
**Example**: "Compare FY26 budget vs actual costs"

---

### Dynamic Discovery Algorithm

```python
def discover_and_generate_sql(user_query: str) -> str:
    """
    Pseudo-code for SQL Generation Agent's discovery workflow.
    This is what happens inside the agent when it processes a query.
    """

    # Step 1: Classify query
    query_type = classify_query(user_query)
    # Returns: "COST" | "BUDGET" | "USAGE" | "COMPARISON"

    # Step 2: Discover datasets
    datasets = call_tool("list_dataset_ids", project_id=PROJECT_ID)
    # Returns: ["cost_dataset", "budget_dataset", "usage_dataset"]

    # Step 3: Match datasets to query type
    if query_type == "COST":
        dataset = find_dataset_matching(datasets, patterns=["*cost*", "*spending*"])
        # Returns: "cost_dataset"

    elif query_type == "BUDGET":
        dataset = find_dataset_matching(datasets, patterns=["*budget*", "*forecast*"])
        # Returns: "budget_dataset"

    elif query_type == "USAGE":
        dataset = find_dataset_matching(datasets, patterns=["*usage*", "*utilization*"])
        # Returns: "usage_dataset"

    elif query_type == "COMPARISON":
        # Multi-table query - discover multiple datasets
        cost_dataset = find_dataset_matching(datasets, patterns=["*cost*"])
        budget_dataset = find_dataset_matching(datasets, patterns=["*budget*"])
        # Returns: ["cost_dataset", "budget_dataset"]

    # Step 4: Discover tables in dataset(s)
    tables = call_tool("list_table_ids",
                       project_id=PROJECT_ID,
                       dataset_id=dataset)
    # Returns: ["cost_analysis"]

    # Step 5: Match table to query type
    table = find_table_matching(tables, patterns=query_type_patterns[query_type])
    # Returns: "cost_analysis"

    # Step 6: Get schema
    schema = call_tool("get_table_info",
                       project_id=PROJECT_ID,
                       dataset_id=dataset,
                       table_id=table)
    # Returns: {"schema": {"fields": [...]}}

    # Step 7: Generate SQL using discovered schema
    sql = generate_sql(user_query, schema, table_fqn=f"{PROJECT_ID}.{dataset}.{table}")
    # Returns: "SELECT SUM(cost) FROM `gac-prod-471220.cost_dataset.cost_analysis` WHERE ..."

    return sql
```

---

### Multi-Table JOIN Example

**User Query**: "Compare FY26 budget vs actual costs by application"

**Discovery Process**:

1. **Classification**: COMPARISON query (needs 2 tables)

2. **Dataset Discovery**:
   ```python
   datasets = list_dataset_ids("gac-prod-471220")
   # Result: ["cost_dataset", "budget_dataset", "usage_dataset"]

   cost_ds = match_pattern(datasets, ["*cost*"])  # "cost_dataset"
   budget_ds = match_pattern(datasets, ["*budget*"])  # "budget_dataset"
   ```

3. **Table Discovery**:
   ```python
   cost_tables = list_table_ids("gac-prod-471220", "cost_dataset")
   # Result: ["cost_analysis"]

   budget_tables = list_table_ids("gac-prod-471220", "budget_dataset")
   # Result: ["budget"]
   ```

4. **Schema Discovery**:
   ```python
   cost_schema = get_table_info("gac-prod-471220", "cost_dataset", "cost_analysis")
   # Columns: date, cloud, application, managed_service, cost

   budget_schema = get_table_info("gac-prod-471220", "budget_dataset", "budget")
   # Columns: date, application, budget_amount, fiscal_year, department
   ```

5. **JOIN SQL Generation**:
   ```sql
   SELECT
     c.application,
     SUM(c.cost) as actual_cost,
     SUM(b.budget_amount) as budget,
     SUM(c.cost) - SUM(b.budget_amount) as variance,
     ROUND((SUM(c.cost) - SUM(b.budget_amount)) / SUM(b.budget_amount) * 100, 2) as variance_pct
   FROM `gac-prod-471220.cost_dataset.cost_analysis` c
   LEFT JOIN `gac-prod-471220.budget_dataset.budget` b
     ON c.application = b.application
     AND c.date = b.date
   WHERE c.date BETWEEN '2025-02-01' AND '2026-01-31'
   GROUP BY c.application
   ORDER BY variance DESC
   LIMIT 10
   ```

---

## ğŸ› ï¸ BigQuery Toolset Architecture

### Toolset Hierarchy

```
google.adk.tools.bigquery.BigQueryToolset
  â”œâ”€ bigquery_schema_toolset (SQL Generation Agent)
  â”‚   â”œâ”€ get_table_info       â† Schema discovery
  â”‚   â”œâ”€ get_dataset_info     â† Dataset metadata
  â”‚   â”œâ”€ list_table_ids       â† Table listing
  â”‚   â””â”€ list_dataset_ids     â† Dataset listing (NEW in v2.0)
  â”‚
  â”œâ”€ bigquery_execution_toolset (Query Execution Agent)
  â”‚   â””â”€ execute_sql          â† Read-only query execution
  â”‚
  â””â”€ bigquery_analytics_toolset (Future expansion)
      â”œâ”€ execute_sql
      â”œâ”€ forecast             â† BigQuery AI forecasting
      â””â”€ ask_data_insights    â† Natural language insights
```

### Configuration

**File**: `_tools/bigquery_tools.py`

```python
from google.adk.tools.bigquery import BigQueryToolset
from google.adk.tools.bigquery.config import BigQueryToolConfig, WriteMode

# Security configuration - BLOCKS all write operations
bigquery_tool_config = BigQueryToolConfig(
    write_mode=WriteMode.BLOCKED,  # Prevents INSERT, UPDATE, DELETE
)

# Schema Discovery Toolset (SQL Generation Agent)
bigquery_schema_toolset = BigQueryToolset(
    tool_filter=[
        "get_table_info",      # CRITICAL: Fetches schema dynamically
        "get_dataset_info",    # Dataset metadata
        "list_table_ids",      # List all tables in dataset
        "list_dataset_ids",    # NEW: List all datasets in project
    ],
    bigquery_tool_config=bigquery_tool_config,
)

# Execution Toolset (Query Execution Agent)
bigquery_execution_toolset = BigQueryToolset(
    tool_filter=["execute_sql"],
    bigquery_tool_config=bigquery_tool_config,
)

# Analytics Toolset (Future - Phase 3)
bigquery_analytics_toolset = BigQueryToolset(
    tool_filter=[
        "execute_sql",
        "forecast",            # BigQuery AI time series forecasting
        "ask_data_insights",   # Natural language data insights
    ],
    bigquery_tool_config=bigquery_tool_config,
)
```

### Security Configuration

**WriteMode.BLOCKED** prevents:
- INSERT statements
- UPDATE statements
- DELETE statements
- DROP statements
- CREATE statements
- ALTER statements
- TRUNCATE statements

**Allowed Operations** (read-only):
- SELECT queries
- WITH clauses (CTEs)
- JOINs
- Aggregations
- Window functions
- Metadata queries (INFORMATION_SCHEMA)

---

## ğŸ“Š Data Flow Diagrams

### Complete Request-Response Flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    USER INPUT                                   â”‚
â”‚         "What is our total cloud cost for FY26?"                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚               ROOT AGENT (Orchestrator)                         â”‚
â”‚    Initializes state = {}                                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          SUB-AGENT 1: SQL Generation                            â”‚
â”‚                                                                 â”‚
â”‚  1. Reads user query                                            â”‚
â”‚  2. Classifies as "COST" query                                  â”‚
â”‚  3. Calls list_dataset_ids("gac-prod-471220")                   â”‚
â”‚     â†’ ["cost_dataset", "budget_dataset", "usage_dataset"]       â”‚
â”‚  4. Matches "cost_dataset" (contains "cost")                    â”‚
â”‚  5. Calls list_table_ids("gac-prod-471220", "cost_dataset")     â”‚
â”‚     â†’ ["cost_analysis"]                                         â”‚
â”‚  6. Calls get_table_info(..., "cost_analysis")                  â”‚
â”‚     â†’ {schema: {fields: [{name: "date", type: "DATE"}, ...]}}   â”‚
â”‚  7. Generates SQL using discovered schema                       â”‚
â”‚                                                                 â”‚
â”‚  Output: state['sql_query'] = "SELECT SUM(cost) ..."           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          SUB-AGENT 2: SQL Validation                            â”‚
â”‚                                                                 â”‚
â”‚  1. Reads state['sql_query']                                    â”‚
â”‚  2. Calls check_forbidden_keywords(sql)                         â”‚
â”‚     â†’ {valid: True}                                             â”‚
â”‚  3. Calls parse_sql_query(sql)                                  â”‚
â”‚     â†’ {valid: True, parsed: "..."}                              â”‚
â”‚  4. Calls validate_sql_security(sql)                            â”‚
â”‚     â†’ {valid: True, message: "SQL is safe"}                     â”‚
â”‚                                                                 â”‚
â”‚  Output: state['validation_result'] = "VALID"                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          SUB-AGENT 3: Query Execution                           â”‚
â”‚                                                                 â”‚
â”‚  1. Reads state['sql_query'] (validated SQL)                    â”‚
â”‚  2. Reads state['validation_result']                            â”‚
â”‚  3. If VALID:                                                   â”‚
â”‚     Calls execute_sql(state['sql_query'])                       â”‚
â”‚     â†’ Executes on BigQuery API                                  â”‚
â”‚     â†’ Returns results                                           â”‚
â”‚                                                                 â”‚
â”‚  Output: state['query_results'] = "total_cost\n27442275.64"    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          SUB-AGENT 4: Insight Synthesis                         â”‚
â”‚                                                                 â”‚
â”‚  1. Reads state['sql_query'] (original question context)        â”‚
â”‚  2. Reads state['query_results'] (raw BigQuery output)          â”‚
â”‚  3. Formats results with business context                       â”‚
â”‚  4. Adds currency formatting, date explanations                 â”‚
â”‚  5. Provides insights and context                               â”‚
â”‚                                                                 â”‚
â”‚  Output: state['final_insights'] = "The total cost for FY26..." â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚               ROOT AGENT (Orchestrator)                         â”‚
â”‚    Returns state['final_insights'] to user                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    USER OUTPUT                                  â”‚
â”‚                                                                 â”‚
â”‚  The total cost for FY26 (February 2025 - January 2026) was    â”‚
â”‚  $27,442,275.64.                                                â”‚
â”‚                                                                 â”‚
â”‚  This represents cloud spending across all providers and        â”‚
â”‚  applications for the current fiscal year.                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### State Dictionary Evolution

```python
# Initial state (empty)
state = {}

# After SQL Generation Agent
state = {
    'sql_query': 'SELECT SUM(cost) as total_cost FROM `gac-prod-471220.cost_dataset.cost_analysis` WHERE date BETWEEN ...'
}

# After SQL Validation Agent
state = {
    'sql_query': '...',
    'validation_result': 'VALID'
}

# After Query Execution Agent
state = {
    'sql_query': '...',
    'validation_result': 'VALID',
    'query_results': 'total_cost\n27442275.64'
}

# After Insight Synthesis Agent (final)
state = {
    'sql_query': '...',
    'validation_result': 'VALID',
    'query_results': '...',
    'final_insights': 'The total cost for FY26 (February 2025 - January 2026) was $27,442,275.64.\n\nThis represents cloud spending across all providers and applications for the current fiscal year.'
}
```

---

## ğŸ”Œ API Specifications

### BigQuery Tool APIs

#### 1. `list_dataset_ids(project_id: str) -> List[str]`

**Purpose**: List all datasets in a GCP project
**Usage**: Dataset discovery in SQL Generation Agent
**Security**: Read-only operation

**Request**:
```python
datasets = list_dataset_ids(project_id="gac-prod-471220")
```

**Response**:
```python
["cost_dataset", "budget_dataset", "usage_dataset"]
```

**Error Handling**:
- Permission denied: "ERROR: Access denied to project gac-prod-471220"
- Invalid project: "ERROR: Project not found: invalid-project-id"

---

#### 2. `list_table_ids(project_id: str, dataset_id: str) -> List[str]`

**Purpose**: List all tables in a BigQuery dataset
**Usage**: Table discovery in SQL Generation Agent
**Security**: Read-only operation

**Request**:
```python
tables = list_table_ids(
    project_id="gac-prod-471220",
    dataset_id="cost_dataset"
)
```

**Response**:
```python
["cost_analysis", "historical_costs"]
```

**Error Handling**:
- Dataset not found: "ERROR: Dataset not found: cost_dataset"
- Permission denied: "ERROR: Access denied to dataset"

---

#### 3. `get_table_info(project_id: str, dataset_id: str, table_id: str) -> Dict`

**Purpose**: Fetch table schema and metadata
**Usage**: Schema discovery in SQL Generation Agent (CRITICAL)
**Security**: Read-only operation

**Request**:
```python
schema = get_table_info(
    project_id="gac-prod-471220",
    dataset_id="cost_dataset",
    table_id="cost_analysis"
)
```

**Response**:
```python
{
    "schema": {
        "fields": [
            {"name": "date", "type": "DATE", "mode": "NULLABLE"},
            {"name": "cto", "type": "STRING", "mode": "NULLABLE"},
            {"name": "cloud", "type": "STRING", "mode": "NULLABLE"},
            {"name": "application", "type": "STRING", "mode": "NULLABLE"},
            {"name": "managed_service", "type": "STRING", "mode": "NULLABLE"},
            {"name": "environment", "type": "STRING", "mode": "NULLABLE"},
            {"name": "cost", "type": "FLOAT64", "mode": "NULLABLE"}
        ]
    },
    "description": "Cloud cost analysis data",
    "numRows": "1500000",
    "creationTime": "1698172800000",
    "lastModifiedTime": "1698345600000"
}
```

**Error Handling**:
- Table not found: "ERROR: Table not found: cost_analysis"
- Permission denied: "ERROR: Access denied to table"

---

#### 4. `get_dataset_info(project_id: str, dataset_id: str) -> Dict`

**Purpose**: Fetch dataset metadata
**Usage**: Optional - for dataset description
**Security**: Read-only operation

**Request**:
```python
info = get_dataset_info(
    project_id="gac-prod-471220",
    dataset_id="cost_dataset"
)
```

**Response**:
```python
{
    "datasetReference": {
        "projectId": "gac-prod-471220",
        "datasetId": "cost_dataset"
    },
    "description": "Cloud cost analysis and tracking",
    "location": "US",
    "creationTime": "1698172800000",
    "lastModifiedTime": "1698345600000"
}
```

---

#### 5. `execute_sql(sql: str) -> str`

**Purpose**: Execute SQL query on BigQuery
**Usage**: Query execution in Query Execution Agent
**Security**: Read-only (WriteMode.BLOCKED)

**Request**:
```python
results = execute_sql("""
    SELECT SUM(cost) as total_cost
    FROM `gac-prod-471220.cost_dataset.cost_analysis`
    WHERE date BETWEEN '2025-02-01' AND '2026-01-31'
""")
```

**Response** (formatted as table):
```
total_cost
27442275.64
```

**Error Handling**:
- Syntax error: "ERROR: Syntax error at line 2: Unexpected token..."
- Table not found: "ERROR: Table not found: gac-prod-471220.cost_dataset.cost_analysis"
- Permission denied: "ERROR: Access denied to table"
- Timeout: "ERROR: Query timeout after 60 seconds"

---

### Validation Tool APIs

#### 1. `check_forbidden_keywords(sql: str) -> dict`

**Purpose**: Detect dangerous SQL keywords
**Usage**: SQL Validation Agent

**Request**:
```python
result = check_forbidden_keywords("SELECT * FROM users")
```

**Response (Safe)**:
```python
{"valid": True}
```

**Response (Unsafe)**:
```python
{"valid": False, "reason": "Contains forbidden keyword: DROP"}
```

---

#### 2. `parse_sql_query(sql: str) -> dict`

**Purpose**: Validate SQL syntax
**Usage**: SQL Validation Agent

**Request**:
```python
result = parse_sql_query("SELECT SUM(cost) FROM table WHERE date > '2025-01-01'")
```

**Response (Valid)**:
```python
{
    "valid": True,
    "parsed": "SELECT SUM(cost) FROM table WHERE date > '2025-01-01'"
}
```

**Response (Invalid)**:
```python
{
    "valid": False,
    "reason": "Parse error: Expected end of statement, got 'FORM'"
}
```

---

#### 3. `validate_sql_security(sql: str) -> dict`

**Purpose**: Complete security validation (combines keyword + syntax checks)
**Usage**: SQL Validation Agent (recommended to use this)

**Request**:
```python
result = validate_sql_security("SELECT SUM(cost) FROM table")
```

**Response (Safe)**:
```python
{"valid": True, "message": "SQL is safe"}
```

**Response (Unsafe)**:
```python
{"valid": False, "reason": "Contains forbidden keyword: DELETE"}
```

---

## ğŸ”’ Security Architecture

### Defense-in-Depth Strategy

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Layer 1: IAM Permissions                     â”‚
â”‚          Service Account with Minimal Permissions               â”‚
â”‚    âœ“ bigquery.datasets.get                                      â”‚
â”‚    âœ“ bigquery.tables.get                                        â”‚
â”‚    âœ“ bigquery.tables.list                                       â”‚
â”‚    âœ“ bigquery.jobs.create (read-only queries)                   â”‚
â”‚    âœ— bigquery.tables.update (DENIED)                            â”‚
â”‚    âœ— bigquery.tables.delete (DENIED)                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Layer 2: BigQuery Toolset Configuration            â”‚
â”‚                  WriteMode.BLOCKED                              â”‚
â”‚    Prevents: INSERT, UPDATE, DELETE, DROP, CREATE, ALTER        â”‚
â”‚    Allows: SELECT, WITH, JOIN, aggregations                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Layer 3: SQL Validation Agent                      â”‚
â”‚         Keyword Blacklist + Syntax Validation                   â”‚
â”‚    âœ“ Detects forbidden keywords (DROP, DELETE, etc.)            â”‚
â”‚    âœ“ Validates SQL syntax                                       â”‚
â”‚    âœ“ Prevents comment injection (-- and /* */)                  â”‚
â”‚    âœ“ Prevents query chaining (semicolons)                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Layer 4: Prompt Engineering                        â”‚
â”‚         Instructions to Generate Safe SQL                       â”‚
â”‚    â€¢ "ONLY SELECT queries allowed"                              â”‚
â”‚    â€¢ "Use fully qualified table names"                          â”‚
â”‚    â€¢ "No semicolons or comments"                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Layer 5: Audit Logging                             â”‚
â”‚         All Queries Logged for Compliance                       â”‚
â”‚    â€¢ User query logged                                          â”‚
â”‚    â€¢ Generated SQL logged                                       â”‚
â”‚    â€¢ Validation result logged                                   â”‚
â”‚    â€¢ Execution result logged                                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Threat Model & Mitigations

| Threat | Mitigation | Layer |
|--------|-----------|-------|
| **SQL Injection** | Parameterized queries not possible (LLM-generated SQL), but validation layer prevents injection patterns | Layer 3 |
| **Destructive Operations** | WriteMode.BLOCKED prevents all write operations | Layer 2 |
| **Privilege Escalation** | Service account has minimal IAM permissions | Layer 1 |
| **Query Chaining** | Semicolon detection in validation | Layer 3 |
| **Comment Injection** | `--` and `/* */` detection in validation | Layer 3 |
| **Data Exfiltration** | Read-only access + audit logs | Layers 1, 5 |
| **Denial of Service** | Query timeout (60s default in BigQuery) | BigQuery API |
| **Schema Tampering** | Read-only IAM permissions | Layer 1 |

### Service Account Configuration

**Recommended Service Account**: `finops-agent@gac-prod-471220.iam.gserviceaccount.com`

**Required IAM Roles**:
```bash
gcloud projects add-iam-policy-binding gac-prod-471220 \
  --member="serviceAccount:finops-agent@gac-prod-471220.iam.gserviceaccount.com" \
  --role="roles/bigquery.dataViewer"

gcloud projects add-iam-policy-binding gac-prod-471220 \
  --member="serviceAccount:finops-agent@gac-prod-471220.iam.gserviceaccount.com" \
  --role="roles/bigquery.jobUser"
```

**What Each Role Grants**:
- `bigquery.dataViewer`: Read access to datasets, tables, and data
- `bigquery.jobUser`: Create and run query jobs

**Authentication**:
```bash
# Option 1: Service account key (production)
export GOOGLE_APPLICATION_CREDENTIALS=/path/to/service-account-key.json

# Option 2: User credentials (development)
gcloud auth application-default login
```

---

## ğŸš€ Deployment Architecture

### Local Development

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Developer Machine                            â”‚
â”‚                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚  finops-cost-data-analyst/                             â”‚    â”‚
â”‚  â”‚    â”œâ”€â”€ agent.py                                        â”‚    â”‚
â”‚  â”‚    â”œâ”€â”€ prompts.py                                      â”‚    â”‚
â”‚  â”‚    â”œâ”€â”€ _tools/                                         â”‚    â”‚
â”‚  â”‚    â””â”€â”€ .env                                            â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                          â”‚                                      â”‚
â”‚                          â–¼                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚  adk web (http://localhost:8000)                       â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼ (GOOGLE_APPLICATION_CREDENTIALS)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   Google Cloud Platform                         â”‚
â”‚                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚  BigQuery (gac-prod-471220)                            â”‚    â”‚
â”‚  â”‚    â”œâ”€â”€ cost_dataset.cost_analysis                      â”‚    â”‚
â”‚  â”‚    â”œâ”€â”€ budget_dataset.budget                           â”‚    â”‚
â”‚  â”‚    â””â”€â”€ usage_dataset.resource_usage                    â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚  Gemini API (gemini-2.0-flash-exp)                     â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Run Locally**:
```bash
cd /path/to/google-adk-agents
adk web --port 8000
# Open http://localhost:8000
# Select "finops-cost-data-analyst" from dropdown
```

---

### Production Deployment (Cloud Run)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         Users                                   â”‚
â”‚              (FinOps Managers, Engineers, CFOs)                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚ HTTPS
                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   Cloud Load Balancer                           â”‚
â”‚                  (Global HTTPS Load Balancer)                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      Cloud Run Service                          â”‚
â”‚              (Serverless Container Runtime)                     â”‚
â”‚                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚  Container Image: finops-agent:v2.0                    â”‚    â”‚
â”‚  â”‚    - Python 3.10+                                      â”‚    â”‚
â”‚  â”‚    - ADK 1.16.0+                                       â”‚    â”‚
â”‚  â”‚    - finops-cost-data-analyst/                         â”‚    â”‚
â”‚  â”‚                                                        â”‚    â”‚
â”‚  â”‚  Environment Variables:                                â”‚    â”‚
â”‚  â”‚    BIGQUERY_PROJECT=gac-prod-471220                    â”‚    â”‚
â”‚  â”‚    ROOT_AGENT_MODEL=gemini-2.0-flash-exp               â”‚    â”‚
â”‚  â”‚                                                        â”‚    â”‚
â”‚  â”‚  Service Account:                                      â”‚    â”‚
â”‚  â”‚    finops-agent@gac-prod-471220.iam.gserviceaccount.comâ”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                          â”‚                                      â”‚
â”‚  Scaling:                â”‚                                      â”‚
â”‚    Min instances: 1      â”‚                                      â”‚
â”‚    Max instances: 100    â”‚                                      â”‚
â”‚    Concurrency: 80       â”‚                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   Google Cloud Platform                         â”‚
â”‚                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚  BigQuery (gac-prod-471220)                            â”‚    â”‚
â”‚  â”‚    â”œâ”€â”€ cost_dataset.cost_analysis (1.5M rows)          â”‚    â”‚
â”‚  â”‚    â”œâ”€â”€ budget_dataset.budget (500K rows)               â”‚    â”‚
â”‚  â”‚    â””â”€â”€ usage_dataset.resource_usage (3M rows)          â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚  Gemini API (gemini-2.0-flash-exp)                     â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚  Cloud Logging (Audit Logs)                            â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚  Cloud Monitoring (Metrics & Alerts)                   â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Deployment Steps**:

1. **Build Container**:
```bash
cd finops-cost-data-analyst
docker build -t gcr.io/gac-prod-471220/finops-agent:v2.0 .
docker push gcr.io/gac-prod-471220/finops-agent:v2.0
```

2. **Deploy to Cloud Run**:
```bash
gcloud run deploy finops-agent \
  --image gcr.io/gac-prod-471220/finops-agent:v2.0 \
  --platform managed \
  --region us-central1 \
  --service-account finops-agent@gac-prod-471220.iam.gserviceaccount.com \
  --set-env-vars BIGQUERY_PROJECT=gac-prod-471220,ROOT_AGENT_MODEL=gemini-2.0-flash-exp \
  --min-instances 1 \
  --max-instances 100 \
  --concurrency 80 \
  --timeout 300 \
  --memory 2Gi \
  --cpu 2
```

3. **Configure Load Balancer** (optional - for custom domain):
```bash
gcloud compute backend-services create finops-agent-backend \
  --global \
  --load-balancing-scheme=EXTERNAL_MANAGED \
  --protocol=HTTPS

gcloud compute url-maps create finops-agent-lb \
  --default-service finops-agent-backend

gcloud compute target-https-proxies create finops-agent-proxy \
  --url-map finops-agent-lb \
  --ssl-certificates finops-cert

gcloud compute forwarding-rules create finops-agent-rule \
  --global \
  --target-https-proxy finops-agent-proxy \
  --ports 443
```

---

## âš¡ Performance Optimization

### Query Performance

#### 1. Partitioning Strategy

**All tables MUST be partitioned by date**:
```sql
CREATE TABLE `gac-prod-471220.cost_dataset.cost_analysis`
PARTITION BY DATE(date)
AS (
  -- data
);
```

**Benefits**:
- 10-100x query speedup for date-filtered queries
- Cost reduction (only scan relevant partitions)
- Required for queries with date filters

**SQL Generation Agent automatically adds date filters**:
```sql
WHERE date BETWEEN '2025-02-01' AND '2026-01-31'  -- Uses partition pruning
```

---

#### 2. Clustering

**Recommended clustering keys**:
```sql
CREATE TABLE `gac-prod-471220.cost_dataset.cost_analysis`
PARTITION BY DATE(date)
CLUSTER BY application, cloud
AS (
  -- data
);
```

**Benefits**:
- Faster filtering on clustered columns
- Reduced I/O for queries like "costs for application X"

---

#### 3. Query Optimization Patterns

**Good** (uses partition pruning + clustering):
```sql
SELECT SUM(cost)
FROM `gac-prod-471220.cost_dataset.cost_analysis`
WHERE date BETWEEN '2025-02-01' AND '2026-01-31'  -- Partition filter
  AND application = 'ML Training'                  -- Cluster filter
```

**Bad** (full table scan):
```sql
SELECT SUM(cost)
FROM `gac-prod-471220.cost_dataset.cost_analysis`
WHERE EXTRACT(YEAR FROM date) = 2025  -- Function on date prevents pruning
```

---

### Agent Performance

#### Model Selection

| Model | Use Case | Speed | Cost | Quality |
|-------|----------|-------|------|---------|
| `gemini-2.0-flash-exp` | Production (default) | Fast | Low | High |
| `gemini-1.5-pro` | Complex JOINs | Medium | Medium | Very High |
| `gemini-1.5-flash` | High-volume simple queries | Very Fast | Very Low | Good |

**Configuration**:
```python
# .env
ROOT_AGENT_MODEL=gemini-2.0-flash-exp  # Used by all agents
```

---

#### Temperature Settings

```python
# SQL Generation Agent
temperature=0.01  # Deterministic SQL generation

# SQL Validation Agent
temperature=0.0   # Strict validation (no creativity)

# Query Execution Agent
temperature=0.0   # Deterministic execution

# Insight Synthesis Agent
temperature=0.1   # Slight creativity for formatting
```

---

#### Schema Caching (Future Enhancement)

**Problem**: Repeated calls to `get_table_info()` slow down queries

**Solution**: Cache schema for 1 hour
```python
# Pseudo-code for future implementation
from functools import lru_cache

@lru_cache(maxsize=10)
def get_table_info_cached(project, dataset, table):
    return get_table_info(project, dataset, table)
```

**Benefits**:
- 90% reduction in schema discovery time
- Reduced BigQuery API calls

---

### Response Time Targets

| Query Type | Target | Current | Optimization |
|-----------|--------|---------|--------------|
| Simple (single table, no JOIN) | < 5s | ~4s | âœ… Met |
| Complex (multi-table JOIN) | < 10s | ~8s | âœ… Met |
| Aggregation (large dataset) | < 15s | ~12s | âœ… Met |

**Measured on**:
- Dataset size: 1.5M rows (cost_analysis)
- Model: gemini-2.0-flash-exp
- Network: 50ms latency to GCP

---

## ğŸ›¡ï¸ Error Handling & Resilience

### Error Categories & Responses

#### 1. Dataset Discovery Errors

**Error**: No datasets found in project
```
User: "What is our total cost?"

SQL Generation Agent:
ERROR: No datasets found in project gac-prod-471220.
Please check:
1. GOOGLE_APPLICATION_CREDENTIALS is set
2. Service account has bigquery.datasets.get permission
3. Project ID is correct in .env
```

---

#### 2. Table Discovery Errors

**Error**: No matching table for query type
```
User: "What is our budget for FY26?"

SQL Generation Agent:
ERROR: Could not find budget table in project gac-prod-471220.
Available datasets: cost_dataset, usage_dataset
Missing: budget_dataset

Please create a dataset with name matching: *budget*, *forecast*, *allocation*
```

---

#### 3. Schema Discovery Errors

**Error**: Permission denied to table
```
SQL Generation Agent:
ERROR: Cannot access table schema for cost_analysis.
Reason: Access Denied: Table gac-prod-471220:cost_dataset.cost_analysis: Permission bigquery.tables.get denied

Fix: Grant bigquery.dataViewer role to service account
```

---

#### 4. SQL Validation Errors

**Error**: Forbidden keyword detected
```
User: "Drop the cost table and show me the data"

SQL Validation Agent:
INVALID: Contains forbidden keyword DROP

SQL queries are READ-ONLY. Only SELECT statements are allowed.
```

---

#### 5. Query Execution Errors

**Error**: Table not found
```
Query Execution Agent:
ERROR: Table not found: gac-prod-471220.cost_dataset.cost_analysis

Please verify:
1. Table exists in BigQuery
2. Dataset name is correct
3. Service account has access
```

**Error**: Query timeout
```
Query Execution Agent:
ERROR: Query timeout after 60 seconds

This query is too complex. Please:
1. Add date filters to reduce data scanned
2. Limit aggregation scope
3. Use LIMIT clause
```

---

### Retry Logic

**BigQuery API Retries** (handled by ADK):
- Transient errors: 3 retries with exponential backoff
- Rate limiting (HTTP 429): 5 retries with backoff
- Timeout: No retry (fail fast)

**Example**:
```python
# ADK automatically retries these errors:
# - HTTP 500 (Internal Server Error)
# - HTTP 503 (Service Unavailable)
# - HTTP 429 (Too Many Requests)

# No retry for:
# - HTTP 400 (Bad Request - fix the query)
# - HTTP 403 (Forbidden - fix permissions)
# - HTTP 404 (Not Found - table doesn't exist)
```

---

### Graceful Degradation

**If schema discovery fails**:
1. Use fallback hint from .env (BIGQUERY_DATASET, BIGQUERY_TABLE)
2. Generate SQL with assumed schema
3. Add warning: "Using fallback schema - results may be inaccurate"

**If validation fails**:
1. Do NOT execute SQL (security first)
2. Return validation error to user
3. Suggest alternative phrasing

**If execution fails**:
1. Return BigQuery error message
2. Provide troubleshooting steps
3. Do NOT retry (user should fix query)

---

## ğŸ§ª Testing Strategy

### 1. Unit Tests

**File**: `test_simple.py`

```python
def test_agent_structure():
    """Verify agent architecture"""
    assert hasattr(root_agent, 'sub_agents')
    assert len(root_agent.sub_agents) == 4
    assert root_agent.sub_agents[0].name == "sql_generation"

def test_toolset_configuration():
    """Verify toolset has correct tools"""
    from _tools import bigquery_schema_toolset

    tools = bigquery_schema_toolset.get_tools()
    tool_names = [t.name for t in tools]

    assert "get_table_info" in tool_names
    assert "list_dataset_ids" in tool_names
    assert "list_table_ids" in tool_names

def test_validation_tools():
    """Test SQL validation functions"""
    from _tools.validation_tools import validate_sql_security

    # Safe SQL
    result = validate_sql_security("SELECT * FROM table")
    assert result["valid"] == True

    # Unsafe SQL
    result = validate_sql_security("DROP TABLE users")
    assert result["valid"] == False
    assert "DROP" in result["reason"]
```

---

### 2. Integration Tests (ADK Eval Framework)

**File**: `eval/eval_data/simple.test.json`

```json
{
  "testCases": [
    {
      "name": "Simple cost query",
      "input": "What is our total cloud cost for FY26?",
      "expectedOutput": {
        "contains": ["$", "FY26", "total cost"],
        "notContains": ["ERROR", "INVALID"]
      }
    },
    {
      "name": "Budget comparison",
      "input": "Compare FY26 budget vs actual costs",
      "expectedOutput": {
        "contains": ["budget", "actual", "variance"],
        "notContains": ["ERROR"]
      }
    },
    {
      "name": "Multi-table discovery",
      "input": "How much did we spend compared to budget in Q2?",
      "expectedOutput": {
        "contains": ["Q2", "spent", "budget"],
        "requiresMultipleTables": true
      }
    }
  ]
}
```

**Run Tests**:
```bash
adk eval --eval-file eval/eval_data/simple.test.json
```

---

### 3. End-to-End Tests

**Manual Test Cases**:

| Test Case | Query | Expected Result | Validates |
|-----------|-------|----------------|-----------|
| Single table - cost | "What is total cost for FY26?" | Returns dollar amount | Cost table discovery |
| Single table - budget | "What is our budget for FY26?" | Returns budget amount | Budget table discovery |
| Single table - usage | "How many compute hours?" | Returns hour count | Usage table discovery |
| Multi-table JOIN | "Budget vs actual for FY26" | Returns comparison | JOIN generation |
| Invalid query | "Drop the cost table" | Returns validation error | Security validation |
| No results | "Cost for year 2050" | Returns "No data found" | Empty result handling |
| Table not found | "Show me xyz data" | Returns helpful error | Error handling |

---

### 4. Performance Tests

**Load Testing**:
```bash
# Simulate 100 concurrent users
locust -f load_test.py --users 100 --spawn-rate 10
```

**Metrics to Track**:
- P50 response time: < 5s
- P95 response time: < 10s
- P99 response time: < 15s
- Error rate: < 1%

---

## ğŸ“Š Monitoring & Observability

### Cloud Logging (Audit Trail)

**What to Log**:
1. User query (input)
2. Classified query type (COST/BUDGET/USAGE)
3. Discovered datasets and tables
4. Generated SQL
5. Validation result
6. Query execution time
7. Result summary (row count, data scanned)
8. Final insights (output)

**Log Structure**:
```json
{
  "timestamp": "2025-10-21T10:30:00Z",
  "user_query": "What is our total cost for FY26?",
  "query_type": "COST",
  "discovered_dataset": "cost_dataset",
  "discovered_table": "cost_analysis",
  "generated_sql": "SELECT SUM(cost) FROM `gac-prod-471220.cost_dataset.cost_analysis` WHERE...",
  "validation_result": "VALID",
  "execution_time_ms": 3500,
  "rows_returned": 1,
  "bytes_scanned": "15MB",
  "final_insights": "The total cost for FY26 was $27,442,275.64..."
}
```

---

### Cloud Monitoring (Metrics & Alerts)

**Key Metrics**:

| Metric | Description | Alert Threshold |
|--------|-------------|----------------|
| `agent/query_count` | Total queries processed | N/A (tracking only) |
| `agent/response_time_p95` | 95th percentile response time | > 10 seconds |
| `agent/error_rate` | Percentage of failed queries | > 5% |
| `agent/validation_failures` | SQL validation failures | > 10% |
| `bigquery/bytes_scanned` | Data scanned per query | > 1GB (cost concern) |
| `bigquery/api_errors` | BigQuery API errors | > 1% |

**Alerting Rules**:
```yaml
# Alert when response time is too high
- name: High Response Time
  condition: agent/response_time_p95 > 10s
  for: 5 minutes
  action: Send email to team

# Alert when error rate spikes
- name: High Error Rate
  condition: agent/error_rate > 5%
  for: 2 minutes
  action: Send page to on-call
```

---

### Dashboard (Looker Studio / Data Studio)

**Recommended Widgets**:

1. **Query Volume Over Time** (line chart)
   - X-axis: Time (hourly)
   - Y-axis: Number of queries
   - Breakdowns: Query type (COST/BUDGET/USAGE)

2. **Response Time Distribution** (histogram)
   - X-axis: Response time (seconds)
   - Y-axis: Frequency
   - Percentile markers: P50, P95, P99

3. **Top Users** (table)
   - Columns: User, Query Count, Avg Response Time
   - Sorted by: Query Count DESC

4. **Error Analysis** (pie chart)
   - Slices: Error types (Validation, Execution, Discovery, etc.)

5. **Cost Efficiency** (scorecard)
   - Metric: Average bytes scanned per query
   - Target: < 100MB

---

## ğŸ”® Future Enhancements

### Phase 3: BigQuery AI Integration (Q4 2025)

#### Forecasting Capability

**Use Case**: "Predict our cloud costs for next quarter"

**Implementation**:
```python
# Enable analytics toolset
sql_generation_agent = LlmAgent(
    tools=[bigquery_analytics_toolset],  # Includes forecast()
)
```

**Generated Query**:
```sql
SELECT *
FROM ML.FORECAST(
  MODEL cost_forecast_model,
  STRUCT(30 AS horizon, 0.95 AS confidence_level)
)
```

**Expected Output**:
```
Predicted cloud costs for next quarter (Q2 2026):
- Predicted spend: $9,200,000 Â± $500,000 (95% confidence)
- Trend: +5% increase compared to Q1
- Key drivers: ML Training (+15%), Data Pipeline (+8%)
```

---

#### Natural Language Insights

**Use Case**: "What patterns do you see in our spending?"

**Implementation**:
```python
# Use ask_data_insights tool
insights = ask_data_insights(
    table="gac-prod-471220.cost_dataset.cost_analysis",
    question="What patterns do you see in our spending?"
)
```

**Expected Output**:
```
Key spending patterns identified:
1. Seasonality: 20% increase in costs during Q4 (year-end projects)
2. Trend: Steady 3% monthly growth over past 6 months
3. Anomaly: ML Training costs spiked 40% in March (investigate)
4. Efficiency: Azure costs decreased 15% after right-sizing (good!)
```

---

### Phase 4: Multi-Cloud Support (2026)

**Goal**: Consolidate costs from AWS, Azure, and GCP

**Architecture**:
```
Cost Data Sources:
â”œâ”€â”€ GCP BigQuery (current)
â”œâ”€â”€ AWS Cost Explorer API
â””â”€â”€ Azure Cost Management API

Unified Schema:
CREATE TABLE `multi_cloud_costs` (
  date DATE,
  cloud_provider STRING,  -- GCP, AWS, Azure
  account_id STRING,
  application STRING,
  service STRING,
  cost FLOAT64,
  currency STRING
)
```

---

## ğŸ“š References

### Google ADK Documentation
- [ADK GitHub](https://github.com/google/adk-examples)
- [BigQuery Toolset API](https://github.com/google/adk-examples/tree/main/python/tools/bigquery)
- [Agent Patterns](https://github.com/google/adk-examples/tree/main/python/agents)

### BigQuery Best Practices
- [Query Optimization](https://cloud.google.com/bigquery/docs/best-practices-performance-overview)
- [Partitioning & Clustering](https://cloud.google.com/bigquery/docs/partitioned-tables)
- [Cost Optimization](https://cloud.google.com/bigquery/docs/best-practices-costs)

### FinOps Foundation
- [FinOps Framework](https://www.finops.org/framework/)
- [Cloud Cost Optimization](https://www.finops.org/projects/finops-cost-optimization/)

---

## Appendix A: File Structure Reference

```
finops-cost-data-analyst/
â”œâ”€â”€ agent.py                          # Root SequentialAgent + all 4 sub-agents
â”œâ”€â”€ prompts.py                        # All agent prompts (centralized)
â”œâ”€â”€ _tools/
â”‚   â”œâ”€â”€ __init__.py                   # Exports toolsets
â”‚   â”œâ”€â”€ bigquery_tools.py             # 3 BigQuery toolsets
â”‚   â””â”€â”€ validation_tools.py           # SQL validation functions
â”œâ”€â”€ eval/
â”‚   â””â”€â”€ eval_data/
â”‚       â””â”€â”€ simple.test.json          # Integration test cases
â”œâ”€â”€ test_simple.py                    # Unit tests
â”œâ”€â”€ .env                              # Environment config (gitignored)
â”œâ”€â”€ .env.example                      # Environment template
â”œâ”€â”€ README.md                         # User documentation
â”œâ”€â”€ CLAUDE.md                         # Developer guide
â”œâ”€â”€ PRD_FinOps_Agent.md              # Product requirements
â””â”€â”€ TECHNICAL_ARCHITECTURE.md         # This document
```

---

## Appendix B: Environment Variables

| Variable | Required | Default | Description |
|----------|----------|---------|-------------|
| `GOOGLE_API_KEY` | No | N/A | Google Gemini API key (if using API key auth) |
| `GOOGLE_APPLICATION_CREDENTIALS` | Yes | N/A | Path to service account key JSON |
| `GOOGLE_CLOUD_PROJECT` | Yes | N/A | GCP project ID |
| `BIGQUERY_PROJECT` | Yes | N/A | BigQuery project ID (usually same as above) |
| `BIGQUERY_DATASET` | No | agent_bq_dataset | Fallback cost dataset name |
| `BIGQUERY_TABLE` | No | cost_analysis | Fallback cost table name |
| `ROOT_AGENT_MODEL` | No | gemini-2.0-flash-exp | Model for all agents |
| `SQL_GENERATOR_MODEL` | No | (uses ROOT_AGENT_MODEL) | Model for SQL Generation |
| `TEMPERATURE` | No | 0.01 | Default temperature for agents |
| `LOG_LEVEL` | No | INFO | Logging level (DEBUG, INFO, WARNING, ERROR) |

---

## Appendix C: SQL Schema Definitions

### Cost Analysis Table

```sql
CREATE TABLE `gac-prod-471220.cost_dataset.cost_analysis` (
  date DATE NOT NULL,
  cto STRING,
  cloud STRING,
  application STRING,
  managed_service STRING,
  environment STRING,
  cost FLOAT64
)
PARTITION BY DATE(date)
CLUSTER BY application, cloud;
```

### Budget Table

```sql
CREATE TABLE `gac-prod-471220.budget_dataset.budget` (
  date DATE NOT NULL,
  application STRING,
  budget_amount FLOAT64,
  fiscal_year STRING,
  department STRING
)
PARTITION BY DATE(date)
CLUSTER BY application, fiscal_year;
```

### Resource Usage Table

```sql
CREATE TABLE `gac-prod-471220.usage_dataset.resource_usage` (
  date DATE NOT NULL,
  resource_type STRING,
  application STRING,
  usage_hours FLOAT64,
  usage_amount FLOAT64
)
PARTITION BY DATE(date)
CLUSTER BY application, resource_type;
```

---

**Document Version**: 2.0
**Last Updated**: October 21, 2025
**Status**: Production Ready
**Implementation**: Dynamic Multi-Table Discovery âš¡

---

**Related Documents**:
- [Product Requirements (PRD)](./PRD_FinOps_Agent.md)
- [User Guide (README)](./README.md)
- [Developer Guide (CLAUDE)](./CLAUDE.md)
