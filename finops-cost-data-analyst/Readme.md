# FinOps Cost Data Analyst Agent

Enterprise-grade multi-agent AI system for cloud financial operations using Google ADK with **multi-table dynamic discovery**.

ğŸ“– **Quick Links**:
- [MIGRATION.md](./MIGRATION.md) - â­ Step-by-step setup guide (start here tomorrow!)
- [DEPLOYMENT_CHECKLIST.md](./DEPLOYMENT_CHECKLIST.md) - Enterprise deployment checklist
- [CLAUDE.md](./CLAUDE.md) - Developer guide
- [PRD_FinOps_Agent.md](./PRD_FinOps_Agent.md) - Product requirements
- [TECHNICAL_ARCHITECTURE.md](./TECHNICAL_ARCHITECTURE.md) - Complete technical documentation

## Architecture Overview

```
Root Agent (SequentialAgent) - "FinOpsCostAnalystOrchestrator"
    â†“ orchestrates via sub_agents=[]
Sub-Agents (LlmAgent instances with tools + output_key)
    â”œâ”€ sql_generation     â†’ state['sql_query'] (tools: BigQuery Schema Discovery)
    â”œâ”€ sql_validation     â†’ state['validation_result'] (tools: Security validation)
    â”œâ”€ query_execution    â†’ state['query_results'] (tools: BigQuery Execution)
    â””â”€ insight_synthesis  â†’ state['final_insights'] (no tools)
```

### Key Innovation: Dynamic Multi-Table Discovery âš¡

Unlike traditional SQL agents with hardcoded schemas, this agent **dynamically discovers datasets AND tables** at runtime using BigQuery's metadata API. This makes it:
- **Portable**: Works with any BigQuery project/dataset
- **Self-healing**: Adapts to schema changes automatically
- **Accurate**: Uses exact schema from source of truth
- **Intelligent**: Automatically routes queries to correct tables (cost/budget/usage)
- **Multi-source**: Generates JOIN queries across datasets for comparison analysis

## How It Works: Example Query

**User asks**: "What is the total cost for FY26?"

### Step-by-Step Flow (with Dynamic Multi-Table Discovery)

1. **SQL Generation Agent** (agent.py:45-58)
   - **Step 1a: Classify Query** - Determines user intent: COST query
   - **Step 1b: Discover Datasets** - Calls `list_dataset_ids(project)`:
     ```python
     ["cost_dataset", "budget_dataset", "usage_dataset"]
     ```
   - **Step 1c: Match Dataset** - Selects "cost_dataset" (matches "*cost*" pattern)
   - **Step 1d: Discover Tables** - Calls `list_table_ids(project, "cost_dataset")`:
     ```python
     ["cost_analysis"]
     ```
   - **Step 1e: Get Schema** - Calls `get_table_info(project, dataset, table)`:
     ```json
     {
       "schema": {"fields": [
         {"name": "date", "type": "DATE"},
         {"name": "cto", "type": "STRING"},
         {"name": "cloud", "type": "STRING"},
         {"name": "application", "type": "STRING"},
         {"name": "managed_service", "type": "STRING"},
         {"name": "environment", "type": "STRING"},
         {"name": "cost", "type": "FLOAT"}
       ]},
       "numRows": "156234"
     }
     ```
   - **Step 1f**: Uses discovered schema + business rules (FY26 = Feb 1, 2025 to Jan 31, 2026)
   - **Step 1g**: Generates SQL:
     ```sql
     SELECT SUM(cost) as total_cost
     FROM `gac-prod-471220.cost_dataset.cost_analysis`
     WHERE date BETWEEN '2025-02-01' AND '2026-01-31'
     ```
   - **Step 1h**: Writes to `state['sql_query']`

2. **SQL Validation Agent** (agent.py:65-77)
   - Reads `state['sql_query']`
   - Uses security validation tools (_tools/validation_tools.py):
     - `check_forbidden_keywords()` - Blocks DROP, DELETE, INSERT, etc.
     - `parse_sql_query()` - Validates SQL syntax
     - `validate_sql_security()` - Comprehensive security check
   - Writes "VALID" to `state['validation_result']`

3. **Query Execution Agent** (agent.py:85-94)
   - Reads `state['sql_query']`
   - Uses BigQuery Execution Toolset (_tools/bigquery_tools.py)
   - Connects to BigQuery with credentials from .env
   - Executes SQL and returns results
   - Writes to `state['query_results']`:
     ```
     total_cost
     27442275.64
     ```

4. **Insight Synthesis Agent** (agent.py:101-110)
   - Reads `state['query_results']` and `state['sql_query']`
   - Formats into business-friendly output with exact numbers
   - Writes to `state['final_insights']`:
     ```
     The total cost for FY26 (February 2025 - January 2026) was $27,442,275.64.

     This represents cloud spending across all providers and applications
     for the current fiscal year.
     ```
   - Returns final answer to user

## Multi-Table Discovery Mechanism

**Q: How does the agent know about schemas, datasets, and tables?**

**A: DYNAMIC MULTI-TABLE DISCOVERY using BigQuery ADK Toolset** âœ…

### Dynamic Discovery Workflow (5 Steps)

When you ask **"What is total cost for FY26?"**, the agent:

#### Step 1: Classify Query
```
User Intent: COST query
Pattern Matching: "cost" keyword detected
Target Data: Cost dataset
```

#### Step 2: Discover All Datasets
```python
list_dataset_ids(project_id="gac-prod-471220")
# Returns: ["cost_dataset", "budget_dataset", "usage_dataset"]
```

#### Step 3: Match Dataset to Query Type
```python
# Pattern matching logic:
# COST queries â†’ *cost*, *spending*, *expense*
# BUDGET queries â†’ *budget*, *forecast*, *allocation*
# USAGE queries â†’ *usage*, *utilization*, *resource*

Selected: "cost_dataset"  # Matches "*cost*" pattern
```

#### Step 4: Discover Tables in Dataset
```python
list_table_ids(
    project_id="gac-prod-471220",
    dataset_id="cost_dataset"
)
# Returns: ["cost_analysis", "historical_costs"]

Selected: "cost_analysis"  # Best match for cost queries
```

#### Step 5: Get Table Schema
```python
get_table_info(
    project_id="gac-prod-471220",
    dataset_id="cost_dataset",
    table_id="cost_analysis"
)
```

**Response**:
```json
{
  "schema": {
    "fields": [
      {"name": "date", "type": "DATE"},
      {"name": "cto", "type": "STRING"},
      {"name": "cloud", "type": "STRING"},
      {"name": "application", "type": "STRING"},
      {"name": "managed_service", "type": "STRING"},
      {"name": "environment", "type": "STRING"},
      {"name": "cost", "type": "FLOAT"}
    ]
  },
  "numRows": "156234"
}
```

#### Step 6: Generate SQL
```sql
SELECT SUM(cost) as total_cost
FROM `gac-prod-471220.cost_dataset.cost_analysis`
WHERE date BETWEEN '2025-02-01' AND '2026-01-31'
```

### Multi-Table JOIN Example

**Query**: "Compare FY26 budget vs actual costs"

**Discovery Process**:
1. **Classify**: COMPARISON query (needs 2 tables)
2. **Discover**: Both cost_dataset AND budget_dataset
3. **Get Schemas**: Fetch schemas for both tables
4. **Generate JOIN**:
```sql
SELECT
  c.application,
  SUM(c.cost) as actual_cost,
  SUM(b.budget_amount) as budget,
  SUM(c.cost) - SUM(b.budget_amount) as variance
FROM `gac-prod-471220.cost_dataset.cost_analysis` c
LEFT JOIN `gac-prod-471220.budget_dataset.budget` b
  ON c.application = b.application
  AND c.date = b.date
WHERE c.date BETWEEN '2025-02-01' AND '2026-01-31'
GROUP BY c.application
ORDER BY variance DESC
LIMIT 10
```

### BigQuery Toolsets (3 Specialized Toolsets)

**1. Schema Discovery Toolset** (SQL Generation Agent)
- `list_dataset_ids`: â­ Lists all datasets in project (NEW - multi-table support)
- `list_table_ids`: â­ Lists all tables in a dataset
- `get_table_info`: â­ Fetches table schema dynamically from BigQuery
- `get_dataset_info`: Fetches dataset metadata

**2. Execution Toolset** (Query Execution Agent)
- `execute_sql`: Executes validated SQL queries (read-only)

**3. Analytics Toolset** (Future expansion - Phase 3)
- `execute_sql`: SQL execution
- `forecast`: BigQuery AI time series forecasting
- `ask_data_insights`: Natural language data insights

### Why Dynamic Multi-Table Discovery?

**Pros** (CURRENT IMPLEMENTATION):
- âœ… **Portable** - Works with ANY BigQuery project/datasets (just change .env)
- âœ… **Self-healing** - Automatically adapts to schema changes
- âœ… **Accurate** - Uses exact schema from source of truth
- âœ… **Intelligent Routing** - Automatically selects correct tables (cost/budget/usage)
- âœ… **Multi-source Analysis** - Generates JOIN queries across datasets
- âœ… **Explorable** - Can discover new tables/datasets without code changes
- âœ… **Future-ready** - Foundation for AI forecasting & insights

**Cons**:
- Adds ~200-300ms for discovery API calls
- Requires additional IAM permissions (`bigquery.datasets.get`, `bigquery.tables.list`)

### Configuration

**Multi-Table Setup** (.env):
```bash
# REQUIRED: Your GCP Project ID
BIGQUERY_PROJECT=gac-prod-471220

# OPTIONAL: Fallback hints (if discovery fails)
BIGQUERY_DATASET=agent_bq_dataset   # Fallback cost dataset
BIGQUERY_TABLE=cost_analysis        # Fallback cost table
```

**Recommended Dataset/Table Names** (for automatic discovery):
- **Cost**: `cost_dataset.cost_analysis`
- **Budget**: `budget_dataset.budget`
- **Usage**: `usage_dataset.resource_usage`

The agent uses pattern matching to automatically discover these datasets/tables - **no hardcoding needed**!

## Prerequisites

1. **Python 3.10+**
2. **Google Cloud Project** with BigQuery enabled
3. **Google ADK**: `pip install google-adk`
4. **Authentication**: `gcloud auth application-default login`
5. **IAM Permissions** (minimum for multi-table discovery):
   - `roles/bigquery.dataViewer` (read datasets, tables, data)
   - `roles/bigquery.jobUser` (create and run queries)
   - Specific permissions needed:
     - `bigquery.datasets.get` (list and describe datasets)
     - `bigquery.tables.get` (get table schema)
     - `bigquery.tables.list` (list tables in dataset)
     - `bigquery.jobs.create` (execute queries)

## Environment Setup

Create `.env` file in project root:

```bash
# =============================================================================
# BigQuery Configuration - Multi-Table Support
# =============================================================================
# REQUIRED: Your GCP Project ID (agent discovers datasets/tables automatically)
BIGQUERY_PROJECT=gac-prod-471220

# OPTIONAL: Fallback hints (used if dynamic discovery fails)
BIGQUERY_DATASET=agent_bq_dataset    # Fallback cost dataset name
BIGQUERY_TABLE=cost_analysis         # Fallback cost table name

# =============================================================================
# Multi-Table FinOps Setup (Recommended Naming)
# =============================================================================
# The agent automatically discovers these based on pattern matching:
#
# 1. COST ANALYSIS (Actual Spending):
#    Dataset: cost_dataset, agent_bq_dataset, costs, spending
#    Table: cost_analysis, cost_data, costs
#
# 2. BUDGET (Allocations & Forecasts):
#    Dataset: budget_dataset, budgets, financial_planning
#    Table: budget, budget_allocations, forecasts
#
# 3. USAGE (Resource Utilization):
#    Dataset: usage_dataset, resource_usage, utilization
#    Table: usage, resource_usage, consumption
#
# =============================================================================

# Model Configuration (Optional)
ROOT_AGENT_MODEL=gemini-2.0-flash-exp      # Model for all agents
```

## BigQuery Table Schemas (3 Datasets)

### 1. Cost Analysis Table (Actual Spending)

```sql
CREATE TABLE `gac-prod-471220.cost_dataset.cost_analysis` (
  date DATE NOT NULL,
  cto STRING,
  cloud STRING,
  application STRING,
  managed_service STRING,
  environment STRING,
  cost FLOAT64
)
PARTITION BY DATE(date)
CLUSTER BY application, cloud;
```

### 2. Budget Table (Allocations & Forecasts)

```sql
CREATE TABLE `gac-prod-471220.budget_dataset.budget` (
  date DATE NOT NULL,
  application STRING,
  budget_amount FLOAT64,
  fiscal_year STRING,
  department STRING
)
PARTITION BY DATE(date)
CLUSTER BY application, fiscal_year;
```

### 3. Resource Usage Table (Utilization Metrics)

```sql
CREATE TABLE `gac-prod-471220.usage_dataset.resource_usage` (
  date DATE NOT NULL,
  resource_type STRING,
  application STRING,
  usage_hours FLOAT64,
  usage_amount FLOAT64
)
PARTITION BY DATE(date)
CLUSTER BY application, resource_type;
```

**Note**: Partitioning by `date` and clustering by application/cloud improves query performance by 10-100x.

## Installation

```bash
# 1. Install dependencies
pip install google-adk python-dotenv

# 2. Authenticate with Google Cloud
gcloud auth application-default login

# 3. Verify installation
python3 test_simple.py
```

## Run the Agent

### Option 1: Web Interface (Recommended)

```bash
# From parent directory (google-adk-agents/)
cd /path/to/google-adk-agents
adk web
```

Then:
1. Visit http://localhost:8000
2. Select `finops-cost-data-analyst` from dropdown
3. Start chatting!

### Option 2: CLI

```bash
cd finops-cost-data-analyst
adk run --agent agent:root_agent
```

### Option 3: Programmatic

```python
import os
os.chdir('/path/to/finops-cost-data-analyst')

from agent import root_agent

# Run query
response = root_agent.run("What is total cost for FY26?")
print(response.state['final_insights'])
```

## Example Queries

### Cost Queries (Single Table)
```
"What is the total cost for FY26?"
"What are the top 3 most expensive applications?"
"Show me GenAI costs by cloud provider"
"Which managed services cost the most in production?"
"Compare FY25 vs FY26 spending"
```

### Budget Queries (Single Table)
```
"What is our budget for FY26?"
"Show me budget allocation by department"
"What was the budget for ML Training in Q2?"
```

### Usage Queries (Single Table)
```
"How many compute hours did we use this month?"
"Show me resource utilization by application"
"What is our total storage usage?"
```

### Comparison Queries (Multi-Table JOINs)
```
"Compare FY26 budget vs actual costs"
"Are we over budget for FY26?"
"Show me applications that exceeded their budget"
"Compare actual costs vs budget vs usage for my application"
"What is the cost per compute hour?"
```

## Project Structure (Current)

```
finops-cost-data-analyst/              â† Run 'adk web' from PARENT directory
â”œâ”€â”€ agent.py                           â† Root SequentialAgent + all sub-agents (ADK entry point)
â”œâ”€â”€ prompts.py                         â† All prompts with DYNAMIC schema workflow
â”œâ”€â”€ _tools/                            â† Tools package (underscore hides from ADK)
â”‚   â”œâ”€â”€ __init__.py                    â† Exports all toolsets
â”‚   â”œâ”€â”€ validation_tools.py            â† SQL security validation functions
â”‚   â””â”€â”€ bigquery_tools.py              â† 3 BigQuery toolsets:
â”‚                                          â€¢ bigquery_schema_toolset (schema discovery)
â”‚                                          â€¢ bigquery_execution_toolset (query execution)
â”‚                                          â€¢ bigquery_analytics_toolset (AI features)
â”œâ”€â”€ eval/
â”‚   â””â”€â”€ eval_data/
â”‚       â””â”€â”€ simple.test.json           â† Eval test cases
â”œâ”€â”€ test_simple.py                     â† Architecture validation test
â”œâ”€â”€ .env                               â† Environment configuration (gitignored)
â”œâ”€â”€ .env.example                       â† Example environment file
â”œâ”€â”€ Readme.md                          â† This file (user documentation)
â””â”€â”€ CLAUDE.md                          â† Developer guide
```

**IMPORTANT**: ADK expects this flat structure. Don't nest `agent.py` in subdirectories.

## Data Flow Details

### State Dictionary (Shared Memory)

```python
state = {
    'sql_query': str,           # From sql_generation (agent.py:47)
    'validation_result': str,    # From sql_validation (agent.py:62)
    'query_results': dict,       # From query_execution (agent.py:82)
    'final_insights': str        # From insight_synthesis (agent.py:98)
}
```

### Sequential Execution Pattern

Each agent:
1. Reads from `state[...]` (previous agent's output)
2. Performs its specialized task
3. Writes to `state[output_key]` for next agent

**No tools on root agent** - only sub-agents have tools.

## Testing

### Structural Test
```bash
python3 test_simple.py
```

Validates:
- Root agent is SequentialAgent
- All sub-agents are LlmAgent
- Each sub-agent has `output_key`
- Tools are correctly attached

### Evaluation Framework
```bash
adk eval --eval-file eval/eval_data/simple.test.json
```

Tests end-to-end queries against expected results.

### Manual Testing
```bash
# Test import
python3 -c "from agent import root_agent; print(root_agent.name)"

# Test with .env
python3 -c "
from dotenv import load_dotenv
load_dotenv()
from agent import root_agent
print(f'Loaded: {root_agent.name} with {len(root_agent.sub_agents)} sub-agents')
"
```

## Key Design Principles

âœ… **SequentialAgent for orchestration** - Root uses `sub_agents=[]`, NOT `tools=[]`
âœ… **LlmAgent for tasks** - Each sub-agent has `output_key` parameter
âœ… **Relative imports** - Use `from .prompts import ...` (not `from prompts import ...`)
âœ… **State-based flow** - Data flows via `state['key']` between agents
âœ… **Tool isolation** - Only sub-agents have tools, never root
âœ… **Security first** - SQL validation before execution
âœ… **Dynamic multi-table discovery** - Automatically discovers datasets/tables at runtime
âœ… **Intelligent routing** - Pattern matching to select correct table (cost/budget/usage)
âœ… **Multi-source JOINs** - Generates comparison queries across datasets
âœ… **Specialized toolsets** - 3 BigQuery toolsets for different purposes (schema, execution, analytics)

## Common Issues & Fixes

### âŒ "Root Agent not found" in adk web
**Fix**: Run `adk web` from **parent directory**, not from inside `finops-cost-data-analyst/`

```bash
# WRONG
cd finops-cost-data-analyst && adk web

# CORRECT
cd google-adk-agents && adk web
```

### âŒ "No module named 'prompts'"
**Fix**: Use **relative imports** in `agent.py`:

```python
# WRONG
from prompts import ROOT_AGENT_DESCRIPTION

# CORRECT
from .prompts import ROOT_AGENT_DESCRIPTION
```

### âŒ BigQuery permission denied
**Fix**: Re-authenticate and check IAM:

```bash
gcloud auth application-default login
gcloud projects get-iam-policy YOUR_PROJECT_ID --flatten="bindings[].members" --filter="bindings.members:user:YOUR_EMAIL"
```

### âŒ "output_key not found in state"
**Fix**: Ensure all sub-agents have `output_key` parameter defined.

## Performance Tuning

### Temperature Settings (agent.py)
- SQL Generation: `0.01` (deterministic SQL)
- SQL Validation: `0.0` (strict security)
- Query Execution: `0.0` (deterministic)
- Insight Synthesis: `0.1` (slight creativity for formatting)

### Model Selection
- **Production**: `gemini-2.0-flash-exp` (fast, cost-effective)
- **Complex Queries**: `gemini-pro` (more capable)
- **Development**: `gemini-2.0-flash-exp` (fastest iteration)

Set via `.env`:
```bash
ROOT_AGENT_MODEL=gemini-2.0-flash-exp
```

## References

- **ADK Documentation**: https://google.github.io/adk-docs/
- **Sequential Agent Pattern**: github.com/google/adk-examples
- **BigQuery Setup**: https://cloud.google.com/bigquery/docs
- **ADK Python SDK**: github.com/google/adk-python

## Architecture Diagram (with Dynamic Schema Discovery)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  User Query: "What is total cost for FY26?"                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Root Agent (SequentialAgent)                                    â”‚
â”‚  - Name: FinOpsCostAnalystOrchestrator                           â”‚
â”‚  - Role: Orchestrates 4 sub-agents sequentially                  â”‚
â”‚  - Tools: None (orchestration only)                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â–¼                  â–¼                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ SQL Generation   â”‚ â”‚ SQL Validation   â”‚ â”‚ Query Execution  â”‚
â”‚ (LlmAgent)       â”‚ â”‚ (LlmAgent)       â”‚ â”‚ (LlmAgent)       â”‚
â”‚                  â”‚ â”‚                  â”‚ â”‚                  â”‚
â”‚ Input:           â”‚ â”‚ Input:           â”‚ â”‚ Input:           â”‚
â”‚ - User query     â”‚ â”‚ - state['sql_    â”‚ â”‚ - state['sql_    â”‚
â”‚                  â”‚ â”‚   query']        â”‚ â”‚   query']        â”‚
â”‚ âš¡ DYNAMIC STEP: â”‚ â”‚                  â”‚ â”‚                  â”‚
â”‚ 1. Calls:        â”‚ â”‚ Tools:           â”‚ â”‚ Tools:           â”‚
â”‚   get_table_info â”‚ â”‚ - check_         â”‚ â”‚ - execute_sql    â”‚
â”‚   (BigQuery API) â”‚ â”‚   forbidden_     â”‚ â”‚   (BigQuery      â”‚
â”‚                  â”‚ â”‚   keywords       â”‚ â”‚   Execution      â”‚
â”‚ 2. Receives:     â”‚ â”‚ - parse_sql_     â”‚ â”‚   Toolset)       â”‚
â”‚   schema.fields  â”‚ â”‚   query          â”‚ â”‚                  â”‚
â”‚   [date, cost,   â”‚ â”‚ - validate_sql_  â”‚ â”‚ Output:          â”‚
â”‚    cto, cloud,   â”‚ â”‚   security       â”‚ â”‚ state['query_    â”‚
â”‚    application,  â”‚ â”‚   (Validation    â”‚ â”‚ results']        â”‚
â”‚    ...] + types  â”‚ â”‚   Toolset)       â”‚ â”‚                  â”‚
â”‚                  â”‚ â”‚                  â”‚ â”‚ Example:         â”‚
â”‚ 3. Generates SQL â”‚ â”‚ Output:          â”‚ â”‚ total_cost       â”‚
â”‚    using         â”‚ â”‚ state['          â”‚ â”‚ 27442275.64      â”‚
â”‚    discovered    â”‚ â”‚ validation_      â”‚ â”‚                  â”‚
â”‚    schema        â”‚ â”‚ result']         â”‚ â”‚                  â”‚
â”‚                  â”‚ â”‚                  â”‚ â”‚                  â”‚
â”‚ Tools:           â”‚ â”‚ Example:         â”‚ â”‚                  â”‚
â”‚ - get_table_info â”‚ â”‚ "VALID"          â”‚ â”‚                  â”‚
â”‚ - get_dataset_   â”‚ â”‚                  â”‚ â”‚                  â”‚
â”‚   info           â”‚ â”‚                  â”‚ â”‚                  â”‚
â”‚ - list_table_ids â”‚ â”‚                  â”‚ â”‚                  â”‚
â”‚   (Schema        â”‚ â”‚                  â”‚ â”‚                  â”‚
â”‚   Toolset)       â”‚ â”‚                  â”‚ â”‚                  â”‚
â”‚                  â”‚ â”‚                  â”‚ â”‚                  â”‚
â”‚ Output:          â”‚ â”‚                  â”‚ â”‚                  â”‚
â”‚ state['sql_      â”‚ â”‚                  â”‚ â”‚                  â”‚
â”‚ query']          â”‚ â”‚                  â”‚ â”‚                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â–¼
                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                  â”‚ Insight          â”‚
                  â”‚ Synthesis        â”‚
                  â”‚ (LlmAgent)       â”‚
                  â”‚                  â”‚
                  â”‚ Input:           â”‚
                  â”‚ - state['query_  â”‚
                  â”‚   results']      â”‚
                  â”‚ - state['sql_    â”‚
                  â”‚   query']        â”‚
                  â”‚                  â”‚
                  â”‚ Tools: None      â”‚
                  â”‚                  â”‚
                  â”‚ Output:          â”‚
                  â”‚ state['final_    â”‚
                  â”‚ insights']       â”‚
                  â”‚                  â”‚
                  â”‚ Example:         â”‚
                  â”‚ "The total cost  â”‚
                  â”‚ for FY26 was     â”‚
                  â”‚ $27,442,275.64.  â”‚
                  â”‚                  â”‚
                  â”‚ This represents  â”‚
                  â”‚ cloud spending   â”‚
                  â”‚ across all       â”‚
                  â”‚ providers..."    â”‚
                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â–¼
                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                  â”‚  User Response     â”‚
                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Legend:
âš¡ = Dynamic schema discovery at runtime
ğŸ“Š = BigQuery API call for metadata
ğŸ”’ = Security validation before execution
```

---

**Built with Google ADK** | Sequential Multi-Agent Workflow | Dynamic Multi-Table Discovery âš¡ | Intelligent Query Routing
